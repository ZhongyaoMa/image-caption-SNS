{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCEY7kaYLk4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import string\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "from wordsegment import load, segment\n",
        "from collections import Counter\n",
        "from scipy import spatial\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.python.keras.preprocessing.image import load_img\n",
        "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.python.keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g17YqUzcL7Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing tag content\n",
        "# separate words of each tag, remove punctuation, etc\n",
        "# make \"#catoftheday\" -> \"cat of the day\"\n",
        "def collect_tags_and_decomposition(path):\n",
        "  tags = pickle.load(open(path, \"rb\"))\n",
        "  print(len(tags))\n",
        "  load()\n",
        "  for key, value in tags.items():  \n",
        "    cur_list = []\n",
        "    for v in value[0]:\n",
        "      cur = v.split('#')[1].lower()\n",
        "      cur = segment(cur)\n",
        "      cur = ' '.join(cur)\n",
        "      if cur:\n",
        "        cur_list.append(cur)\n",
        "    tags[key] = cur_list\n",
        "  return tags\n",
        "tags = collect_tags_and_decomposition(\"final-imgs.pickle\")\n",
        "print(len(tags))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW_MrReIL8_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# group all tags and select popular tags\n",
        "# select images with at least one of the popular tags\n",
        "# save {image id : list of popular tags} in dictionary\n",
        "def filter_images_with_popular_tags(tags):\n",
        "  popular_tags = [v for value in tags.values() for v in value]\n",
        "  popular_tags = Counter(popular_tags).most_common(500)\n",
        "  popular_tags = [k[0] for k in popular_tags]\n",
        "  image_to_tag_mapping = dict()\n",
        "  for key, value in tags.items():\n",
        "    target_value = []\n",
        "    for v in value:\n",
        "      if v in popular_tags:\n",
        "        target_value.append(v)\n",
        "    if target_value:\n",
        "      image_to_tag_mapping[key] = target_value\n",
        "  return popular_tags, image_to_tag_mapping\n",
        "\n",
        "popular_tags, image_to_tag_mapping = filter_images_with_popular_tags(tags)\n",
        "print(len(popular_tags))\n",
        "print(len(image_to_tag_mapping))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz3sJgxeL-sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode each popular tag into a 512 vector using universal sentence encoding \n",
        "# store the encoding in a list with the same length as popular_tags\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "def sentence_encode_tags(popular_tags):\n",
        "  return embed(popular_tags)\n",
        "encode_tags = sentence_encode_tags(popular_tags)\n",
        "print(len(encode_tags))\n",
        "tree = spatial.KDTree(encode_tags)   # important !!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ2C7UTDMCi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make one predictions of each selected image (with at least one popular tag) using pre-trained VGG16 model\n",
        "def make_vgg_predictions(directory, image_to_tag_mapping_keys):\n",
        "\tvgg_model = VGG16()\n",
        "\tvgg_model = Model(inputs = vgg_model.inputs, outputs = vgg_model.layers[-1].output)\n",
        "\tvgg_predictions = dict()\n",
        "\ttemp = 0\n",
        "\tfor name in os.listdir(directory):\n",
        "\t\tif temp % 100 == 0:\n",
        "\t\t\tprint(temp)\n",
        "\t\ttemp += 1 \n",
        "\t\tfilename = directory + name\n",
        "\t\tname = name.split('.')[0]\n",
        "\t\tif name not in image_to_tag_mapping_keys:\n",
        "\t\t\tcontinue\n",
        "\t\timage = load_img(filename, target_size=(224, 224))\n",
        "\t\timage = img_to_array(image)  # (224, 224, 3)\n",
        "\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t\timage = preprocess_input(image)\n",
        "\t\tfeature = vgg_model.predict(image, verbose=0)\n",
        "\t\tlabel = decode_predictions(feature)[0]\n",
        "\t\tvgg_predictions[name] = label[0][1].replace(\"_\", \" \")\n",
        "\treturn vgg_predictions\n",
        "\t\n",
        "vgg_predictions = make_vgg_predictions('images/', image_to_tag_mapping.keys())\n",
        "print(len(vgg_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuYqhbyJMGJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode prediction of each image into a 512 vector using universal sentence encoding \n",
        "def sentence_encode_vgg_predictions(vgg_predictions):\n",
        "  encode_predictions = dict()\n",
        "  for key, value in vgg_predictions.items():\n",
        "    encode_predictions[key] = embed([value])[0]\n",
        "  return encode_predictions\n",
        "encode_predictions = sentence_encode_vgg_predictions(vgg_predictions)\n",
        "print(len(encode_predictions))\n",
        "print(len(list(encode_predictions.values())[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuSev5iFMIh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find the top k nearest encoded popular tag for each encoded prediction\n",
        "def euclidean_find_nearest_popular_tags(popular_tags, tree, encode_predictions):\n",
        "  euclidean_final_tag_predictions = dict()\n",
        "  for key, value in encode_predictions.items():\n",
        "    euclidean_final_tag_predictions[key] = [popular_tags[i] for i in tree.query(value, k = 36)[1]]\n",
        "  return euclidean_final_tag_predictions\n",
        "euclidean_final_tag_predictions = euclidean_find_nearest_popular_tags(popular_tags, tree, encode_predictions)\n",
        "print(len(euclidean_final_tag_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgjr7k68MJ4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if the top k prediction has at least one match with the true tag set, count as correct\n",
        "# calculate the prediction accuracy\n",
        "# used for both euclidean and logistic regression  !!!\n",
        "def calculate_correctness(image_to_tag_mapping, final_tag_predictions):\n",
        "  correct_num = 0\n",
        "  for key, value in final_tag_predictions.items():\n",
        "    if not set(value).isdisjoint(image_to_tag_mapping[key]):\n",
        "      correct_num += 1\n",
        "  return correct_num / len(image_to_tag_mapping)\n",
        "euclidean_correctness = calculate_correctness(image_to_tag_mapping, euclidean_final_tag_predictions)\n",
        "print(euclidean_correctness)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOPiSTqDML5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_predict_one_image(filename, tree, popular_tags):\n",
        "  vgg_model = VGG16()\n",
        "  vgg_model = Model(inputs = vgg_model.inputs, outputs = vgg_model.layers[-1].output)\n",
        "  image = load_img(filename, target_size=(224, 224))\n",
        "  image = img_to_array(image)  # (224, 224, 3)\n",
        "  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "  image = preprocess_input(image)\n",
        "  feature = vgg_model.predict(image, verbose=0)\n",
        "  label = decode_predictions(feature)[0][0][1].replace(\"_\", \" \")\n",
        "  print(label)\n",
        "  encode_prediction = embed([label])[0]\n",
        "  euclidean_final_tag_prediction = [\"#\" + popular_tags[i].replace(\" \", \"\") for i in tree.query(encode_prediction, k = 12)[1]]\n",
        "  return euclidean_final_tag_prediction\n",
        " \n",
        "# euclidean_predict_one_image(\"cat.jpg\", tree, popular_tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg0uVIu_MRCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# logistic regression\n",
        "# train test split of image keys\n",
        "random.seed(123)\n",
        "train_ratio = 0.8\n",
        "all_image_keys = list(image_to_tag_mapping.keys())\n",
        "random.shuffle(all_image_keys)\n",
        "train_size = int(len(all_image_keys) * train_ratio)\n",
        "train_image_keys = all_image_keys[:train_size]\n",
        "test_image_keys = all_image_keys[train_size:]\n",
        "print(\"train size: \" + str(len(train_image_keys)))\n",
        "print(\"test size: \" + str(len(test_image_keys)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeEFg6z2MeFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# used to prepare both train data and test data separately\n",
        "def log_reg_prepare_data_matrix(target_image_keys, encode_predictions, image_to_tag_mapping, popular_tags, encode_tags):\n",
        "  # X : encode_cross_popular_tag      y : target_binary\n",
        "  encode_cross_popular_tag = []  # number of image * number of popular tags\n",
        "  target_binary = []             # 1 if the tag is in popular tag, 0 otherwise\n",
        "  for key in target_image_keys:\n",
        "    for i in range(len(encode_tags)):   \n",
        "      encode_cross_popular_tag.append(encode_tags[i] * encode_predictions[key])\n",
        "    cur_target = [0] * len(encode_tags)\n",
        "    for j in [popular_tags.index(item) for item in image_to_tag_mapping[key]]:\n",
        "      cur_target[j] = 1\n",
        "    target_binary.extend(cur_target)\n",
        "  return encode_cross_popular_tag, target_binary\n",
        "  \n",
        "# encode_predictions ----- {id: vector length 512}\n",
        "# image_to_tag_mapping ----- {id: list of popular tags appeared}\n",
        "# popular_tags ----- list of tags\n",
        "# encode_tags ----- list of vector (length 512)\n",
        "# return: X, y from train data with keys \"train_image_keys\"\n",
        "X_train, y_train = log_reg_prepare_data_matrix(train_image_keys, encode_predictions, image_to_tag_mapping, popular_tags, encode_tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LHI6TT0MgRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# logistic regression model with X_train and y_train\n",
        "def log_reg_model_construction(X_train, y_train):\n",
        "  # down sampling \n",
        "  index_class_0 = [i for i in range(len(y_train)) if y_train[i] == 0]   \n",
        "  index_class_1 = [i for i in range(len(y_train)) if y_train[i] == 1]   \n",
        "  index_class_0_down_sample = np.random.choice(index_class_0, size = len(index_class_1) * 5, replace = False)\n",
        "  y_train = [y_train[i] for i in index_class_1] + [y_train[i] for i in index_class_0_down_sample]\n",
        "  X_train = [X_train[i] for i in index_class_1] + [X_train[i] for i in index_class_0_down_sample]\n",
        "  print(len(X_train))\n",
        "  print(len(X_train[0]))\n",
        "  print(len(y_train))\n",
        "\n",
        "  scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "  X_train = scaler.transform(X_train)    # standardization\n",
        "  log_reg_model = LogisticRegression(max_iter = 1000, n_jobs = -1, tol = 0.001, solver = 'sag', verbose = 0)\n",
        "  log_reg_model.fit(X_train, y_train)\n",
        "  print(\"logistic model fitting done\")\n",
        "\n",
        "  return log_reg_model, scaler\n",
        "\n",
        "log_reg_model, scaler = log_reg_model_construction(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYy5osRtMhAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate test data accuracy\n",
        "def log_reg_find_nearest_popular_tags(test_image_keys, log_reg_model, scaler, X_test, y_test, popular_tags):\n",
        "  X_test = scaler.transform(X_test)    # standardization\n",
        "  log_reg_accuracy = log_reg_model.score(X_test, y_test)   # accuracy is not much useful in this case\n",
        "  probability_table = log_reg_model.predict_proba(X_test)[:, 1]   # probability that the label is 1\n",
        "  log_reg_final_tag_predictions = dict()\n",
        "  j = 0  # where we are in the iteration of test_image_keys\n",
        "  temp = 0\n",
        "  for i in range(0, len(probability_table), len(popular_tags)):\n",
        "     if temp % 10 == 0:\n",
        "       print(temp)\n",
        "     temp += 1\n",
        "     cur_proba_list = probability_table[i: i + len(popular_tags)]\n",
        "     index_list = sorted(range(len(cur_proba_list)), key = lambda k: cur_proba_list[k])[-20:] \n",
        "     log_reg_final_tag_predictions[test_image_keys[j]] = [popular_tags[i] for i in index_list]\n",
        "     j += 1\n",
        "  return log_reg_final_tag_predictions, log_reg_accuracy\n",
        "\n",
        "X_test, y_test = log_reg_prepare_data_matrix(test_image_keys, encode_predictions, image_to_tag_mapping, popular_tags, encode_tags)\n",
        "print(\"test data preparation done!\")\n",
        "log_reg_final_tag_predictions, log_reg_accuracy = log_reg_find_nearest_popular_tags(test_image_keys, log_reg_model, scaler, X_test, y_test, popular_tags)\n",
        "print(\"logistic regression test data prediction done!\")\n",
        "print(log_reg_accuracy)\n",
        "log_reg_correctness = calculate_correctness(image_to_tag_mapping, log_reg_final_tag_predictions)\n",
        "print(\"calculate correctness done!\")\n",
        "print(log_reg_correctness)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I8UAe-iMpz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict tags from a brand-new image\n",
        "def log_reg_predict_one_image(filename, log_reg_model, scaler, encode_tags, popular_tags):\n",
        "  vgg_model = VGG16()\n",
        "  vgg_model = Model(inputs = vgg_model.inputs, outputs = vgg_model.layers[-1].output)\n",
        "  image = load_img(filename, target_size=(224, 224))\n",
        "  image = img_to_array(image)  # (224, 224, 3)\n",
        "  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "  image = preprocess_input(image)\n",
        "  feature = vgg_model.predict(image, verbose=0)\n",
        "  label = decode_predictions(feature)[0][0][1].replace(\"_\", \" \")\n",
        "  encode_prediction = embed([label])[0]\n",
        "  encode_cross_popular_tag = []\n",
        "  for i in range(len(encode_tags)):\n",
        "    encode_cross_popular_tag.append(encode_tags[i] * encode_prediction)\n",
        "  encode_cross_popular_tag = scaler.transform(encode_cross_popular_tag)  # standardization\n",
        "  probability_table = log_reg_model.predict_proba(encode_cross_popular_tag)[:, 1]  # probability that the label is 1\n",
        "  index_list = sorted(range(len(probability_table)), key = lambda k: probability_table[k])[-12:]   # 12 index with the largest probability\n",
        "  final_tag_prediction = [\"#\" + popular_tags[i].replace(\" \", \"\") for i in index_list]\n",
        "  return final_tag_prediction\n",
        " \n",
        "# log_reg_predict_one_image(\"cat.jpg\", log_reg_model, scaler, encode_tags, popular_tags)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}